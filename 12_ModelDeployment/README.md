# 12. æ¨¡å‹éƒ¨ç½² | Model Deployment

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](../LICENSE)

## ğŸ“‹ ç›®éŒ„ | Table of Contents

- [æ¨¡å¡Šæ¦‚è¿°](#æ¨¡å¡Šæ¦‚è¿°)
- [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
- [æ–‡ä»¶çµæ§‹](#æ–‡ä»¶çµæ§‹)
- [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
- [API æ–‡æª”](#api-æ–‡æª”)
- [æ€§èƒ½æ¸¬è©¦](#æ€§èƒ½æ¸¬è©¦)
- [ç”Ÿç”¢éƒ¨ç½²](#ç”Ÿç”¢éƒ¨ç½²)
- [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)
- [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

---

## ğŸ¯ æ¨¡å¡Šæ¦‚è¿°

æœ¬æ¨¡å¡Šæ¼”ç¤ºå¦‚ä½•å°‡è¨“ç·´å¥½çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹éƒ¨ç½²ç‚ºç”Ÿç”¢ç´š REST API æœå‹™ï¼Œæ¶µè“‹å¾æ¨¡å‹è¨“ç·´ã€API é–‹ç™¼ã€æ¸¬è©¦åˆ°æ€§èƒ½å„ªåŒ–çš„å®Œæ•´æµç¨‹ã€‚

### å­¸ç¿’ç›®æ¨™

- âœ… ç†è§£æ¨¡å‹éƒ¨ç½²çš„åŸºæœ¬æ¦‚å¿µå’Œæµç¨‹
- âœ… æŒæ¡ Flask æ¡†æ¶æ§‹å»º REST API
- âœ… å­¸ç¿’æ¨¡å‹åºåˆ—åŒ–å’Œç‰ˆæœ¬ç®¡ç†
- âœ… å¯¦ç¾å¥åº·æª¢æŸ¥å’Œç›£æ§ç«¯é»
- âœ… é€²è¡Œæ€§èƒ½æ¸¬è©¦å’Œå„ªåŒ–
- âœ… äº†è§£ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²æ–¹æ¡ˆ

### æŠ€è¡“æ£§

| æŠ€è¡“ | ç”¨é€” | ç‰ˆæœ¬ |
|------|------|------|
| Flask | Web æ¡†æ¶ | 2.3+ |
| scikit-learn | æ©Ÿå™¨å­¸ç¿’ | 1.3+ |
| joblib | æ¨¡å‹åºåˆ—åŒ– | 1.3+ |
| requests | HTTP å®¢æˆ¶ç«¯ | 2.31+ |
| gunicorn | WSGI æœå‹™å™¨ | 21.2+ |

---

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### 1. æ¨¡å‹éƒ¨ç½²æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨¡å‹è¨“ç·´    â”‚â”€â”€â”€>â”‚ æ¨¡å‹åºåˆ—åŒ–   â”‚â”€â”€â”€>â”‚ API é–‹ç™¼    â”‚â”€â”€â”€>â”‚ æœå‹™éƒ¨ç½²     â”‚
â”‚ Training    â”‚    â”‚ Serializationâ”‚    â”‚ API Dev     â”‚    â”‚ Deployment   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                    â†“                   â†“                   â†“
  æ•¸æ“šé è™•ç†          ä¿å­˜æ¨¡å‹æ–‡ä»¶         å¯¦ç¾ç«¯é»           é…ç½®æœå‹™å™¨
  ç‰¹å¾µå·¥ç¨‹            ç‰ˆæœ¬ç®¡ç†             éŒ¯èª¤è™•ç†           ç›£æ§æ—¥èªŒ
  æ¨¡å‹è©•ä¼°            å…ƒæ•¸æ“šè¨˜éŒ„           æ€§èƒ½å„ªåŒ–           æ“´å±•éƒ¨ç½²
```

### 2. REST API è¨­è¨ˆ

- **ç«¯é» (Endpoints)**: å®šç¾©æ¸…æ™°çš„ URL è·¯å¾‘
- **HTTP æ–¹æ³•**: GET (æŸ¥è©¢), POST (å‰µå»º/é æ¸¬)
- **è«‹æ±‚æ ¼å¼**: JSON
- **éŸ¿æ‡‰æ ¼å¼**: JSON with status code
- **éŒ¯èª¤è™•ç†**: çµ±ä¸€çš„éŒ¯èª¤éŸ¿æ‡‰æ ¼å¼

### 3. æ¨¡å‹åºåˆ—åŒ–

ä½¿ç”¨ `joblib` ä¿å­˜å’ŒåŠ è¼‰æ¨¡å‹:
- æ¨¡å‹æ–‡ä»¶ (`.pkl`)
- é è™•ç†å™¨ (scaler, encoder ç­‰)
- å…ƒæ•¸æ“š (ç‰¹å¾µåç¨±ã€ç‰ˆæœ¬ä¿¡æ¯ç­‰)

---

## ğŸ“ æ–‡ä»¶çµæ§‹

```
12_ModelDeployment/
â”œâ”€â”€ 01_flask_api_deployment.py      # Flask REST API å¯¦ç¾ (500è¡Œ)
â”‚   â”œâ”€â”€ Part 1: è¨“ç·´ä¸¦ä¿å­˜æ¨¡å‹
â”‚   â”œâ”€â”€ Part 2: å‰µå»º Flask API
â”‚   â”œâ”€â”€ Part 3: API ç«¯é»å®šç¾©
â”‚   â””â”€â”€ Part 4: éŒ¯èª¤è™•ç†
â”‚
â”œâ”€â”€ 02_model_serving_example.py     # å®¢æˆ¶ç«¯å’Œæ€§èƒ½æ¸¬è©¦ (400è¡Œ)
â”‚   â”œâ”€â”€ Part 1: API å®¢æˆ¶ç«¯å°è£
â”‚   â”œâ”€â”€ Part 2: åŸºæœ¬èª¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ Part 3: æ‰¹é‡é æ¸¬ç¤ºä¾‹
â”‚   â”œâ”€â”€ Part 4: æ€§èƒ½æ¸¬è©¦
â”‚   â””â”€â”€ Part 5: éŒ¯èª¤è™•ç†æ¸¬è©¦
â”‚
â”œâ”€â”€ requirements.txt                # éƒ¨ç½²ä¾è³´
â”œâ”€â”€ README.md                       # æœ¬æ–‡ä»¶
â”‚
â”œâ”€â”€ saved_models/                   # æ¨¡å‹æ–‡ä»¶ç›®éŒ„ (è‡ªå‹•ç”Ÿæˆ)
â”‚   â”œâ”€â”€ iris_model.pkl             # è¨“ç·´å¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ iris_scaler.pkl            # ç‰¹å¾µç¸®æ”¾å™¨
â”‚   â””â”€â”€ metadata.json              # æ¨¡å‹å…ƒæ•¸æ“š
â”‚
â””â”€â”€ api.log                        # API æ—¥èªŒ (è‡ªå‹•ç”Ÿæˆ)
```

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æ­¥é©Ÿ 1: å®‰è£ä¾è³´

```bash
# é€²å…¥æ¨¡å¡Šç›®éŒ„
cd 12_ModelDeployment

# å®‰è£ä¾è³´
pip install -r requirements.txt

# æˆ–ä½¿ç”¨é …ç›®æ ¹ç›®éŒ„çš„ä¾è³´æ–‡ä»¶
pip install -r ../requirements.txt
```

### æ­¥é©Ÿ 2: å•Ÿå‹• API æœå‹™å™¨

```bash
# é‹è¡Œ Flask æœå‹™å™¨
python 01_flask_api_deployment.py
```

è¼¸å‡ºç¤ºä¾‹:
```
================================================================================
Part 1: è¨“ç·´ä¸¦ä¿å­˜æ¨¡å‹ | Training and Saving Model
================================================================================

[1/5] åŠ è¼‰æ•¸æ“š...
æ•¸æ“šé›†å½¢ç‹€: (150, 4)
è¨“ç·´é›†æº–ç¢ºç‡: 1.0000
æ¸¬è©¦é›†æº–ç¢ºç‡: 1.0000

âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: saved_models/

================================================================================
å•Ÿå‹• Flask æœå‹™å™¨ | Starting Flask Server
================================================================================

æœå‹™å™¨é…ç½®:
  - åœ°å€: http://localhost:5000
  - èª¿è©¦æ¨¡å¼: é–‹å•Ÿ

* Running on http://0.0.0.0:5000
```

### æ­¥é©Ÿ 3: æ¸¬è©¦ API (æ–°çµ‚ç«¯)

åœ¨å¦ä¸€å€‹çµ‚ç«¯ä¸­é‹è¡Œæ¸¬è©¦è…³æœ¬:

```bash
# é‹è¡Œå®¢æˆ¶ç«¯æ¸¬è©¦
python 02_model_serving_example.py
```

æˆ–ä½¿ç”¨ `curl` å‘½ä»¤:

```bash
# å¥åº·æª¢æŸ¥
curl http://localhost:5000/health

# æ¨¡å‹ä¿¡æ¯
curl http://localhost:5000/model_info

# å–®å€‹é æ¸¬
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}'
```

---

## ğŸ“¡ API æ–‡æª”

### åŸºæœ¬ä¿¡æ¯

- **Base URL**: `http://localhost:5000`
- **Content-Type**: `application/json`
- **Response Format**: JSON

### ç«¯é»åˆ—è¡¨

#### 1. GET `/` - API é¦–é 

ç²å– API åŸºæœ¬ä¿¡æ¯å’Œå¯ç”¨ç«¯é»åˆ—è¡¨ã€‚

**éŸ¿æ‡‰ç¤ºä¾‹:**
```json
{
  "service": "Iris Classification API",
  "version": "1.0.0",
  "model_loaded": true,
  "endpoints": {
    "GET /": "API ä¿¡æ¯",
    "GET /health": "å¥åº·æª¢æŸ¥",
    "POST /predict": "å–®å€‹é æ¸¬"
  }
}
```

#### 2. GET `/health` - å¥åº·æª¢æŸ¥

æª¢æŸ¥ API æœå‹™å’Œæ¨¡å‹åŠ è¼‰ç‹€æ…‹ã€‚

**éŸ¿æ‡‰ç¤ºä¾‹:**
```json
{
  "status": "healthy",
  "timestamp": "2025-11-18T10:00:00",
  "components": {
    "model": true,
    "scaler": true,
    "metadata": true
  }
}
```

**ç‹€æ…‹ç¢¼:**
- `200`: æœå‹™å¥åº·
- `503`: æœå‹™ä¸å¯ç”¨

#### 3. GET `/model_info` - æ¨¡å‹ä¿¡æ¯

ç²å–æ¨¡å‹è©³ç´°ä¿¡æ¯å’Œæ€§èƒ½æŒ‡æ¨™ã€‚

**éŸ¿æ‡‰ç¤ºä¾‹:**
```json
{
  "model_type": "RandomForestClassifier",
  "model_version": "1.0.0",
  "trained_date": "2025-11-18T10:00:00",
  "test_score": 1.0,
  "n_features": 4,
  "features": [
    "sepal length (cm)",
    "sepal width (cm)",
    "petal length (cm)",
    "petal width (cm)"
  ],
  "target_names": ["setosa", "versicolor", "virginica"]
}
```

#### 4. POST `/predict` - å–®å€‹é æ¸¬

å°å–®å€‹æ¨£æœ¬é€²è¡Œé æ¸¬ã€‚

**è«‹æ±‚é«”:**
```json
{
  "features": [5.1, 3.5, 1.4, 0.2]
}
```

**éŸ¿æ‡‰ç¤ºä¾‹:**
```json
{
  "prediction": 0,
  "prediction_label": "setosa",
  "probabilities": {
    "setosa": 0.98,
    "versicolor": 0.01,
    "virginica": 0.01
  },
  "confidence": 0.98,
  "timestamp": "2025-11-18T10:00:00",
  "model_version": "1.0.0"
}
```

**éŒ¯èª¤éŸ¿æ‡‰:**
```json
{
  "error": "æœŸæœ› 4 å€‹ç‰¹å¾µï¼Œä½†æ”¶åˆ° 3 å€‹"
}
```

#### 5. POST `/predict_batch` - æ‰¹é‡é æ¸¬

å°å¤šå€‹æ¨£æœ¬é€²è¡Œæ‰¹é‡é æ¸¬ã€‚

**è«‹æ±‚é«”:**
```json
{
  "samples": [
    [5.1, 3.5, 1.4, 0.2],
    [6.2, 2.9, 4.3, 1.3],
    [7.3, 2.9, 6.3, 1.8]
  ]
}
```

**éŸ¿æ‡‰ç¤ºä¾‹:**
```json
{
  "results": [
    {
      "sample_id": 0,
      "prediction": 0,
      "prediction_label": "setosa",
      "confidence": 0.98
    },
    ...
  ],
  "count": 3,
  "timestamp": "2025-11-18T10:00:00"
}
```

**é™åˆ¶:**
- æœ€å¤§æ‰¹é‡å¤§å°: 1000 å€‹æ¨£æœ¬

#### 6. POST `/predict_proba` - æ¦‚ç‡é æ¸¬

ç²å–è©³ç´°çš„æ¦‚ç‡åˆ†å¸ƒã€‚

**è«‹æ±‚é«”:**
```json
{
  "features": [5.8, 2.7, 5.1, 1.9]
}
```

**éŸ¿æ‡‰ç¤ºä¾‹:**
```json
{
  "probabilities": [
    {
      "class_id": 2,
      "class_name": "virginica",
      "probability": 0.92,
      "percentage": "92.00%"
    },
    ...
  ],
  "most_likely": "virginica",
  "confidence": 0.92
}
```

---

## ğŸ“Š æ€§èƒ½æ¸¬è©¦

### é‹è¡Œæ€§èƒ½æ¸¬è©¦

```bash
python 02_model_serving_example.py
```

### å…¸å‹æ€§èƒ½æŒ‡æ¨™

åŸºæ–¼ 100 æ¬¡è«‹æ±‚çš„æ¸¬è©¦çµæœ:

| æŒ‡æ¨™ | å€¼ |
|------|-----|
| å¹³å‡å»¶é² | ~15 ms |
| P95 å»¶é² | ~25 ms |
| P99 å»¶é² | ~35 ms |
| ååé‡ | ~60 req/s |

### æ‰¹é‡é æ¸¬æ€§èƒ½

| æ‰¹é‡å¤§å° | ç¸½è€—æ™‚ | å¹³å‡å»¶é² | ååé‡ |
|---------|--------|---------|--------|
| 1 | 15 ms | 15.0 ms | 66 req/s |
| 10 | 25 ms | 2.5 ms | 400 req/s |
| 50 | 60 ms | 1.2 ms | 833 req/s |
| 100 | 100 ms | 1.0 ms | 1000 req/s |

**çµè«–**: æ‰¹é‡é æ¸¬å¯é¡¯è‘—æå‡ååé‡ã€‚

---

## ğŸš¢ ç”Ÿç”¢éƒ¨ç½²

### 1. ä½¿ç”¨ Gunicorn (Linux/Mac)

```bash
# å®‰è£ Gunicorn
pip install gunicorn

# å•Ÿå‹•æœå‹™ (4å€‹å·¥ä½œé€²ç¨‹)
gunicorn -w 4 -b 0.0.0.0:5000 01_flask_api_deployment:app

# ä½¿ç”¨é…ç½®æ–‡ä»¶
gunicorn -c gunicorn_config.py 01_flask_api_deployment:app
```

**gunicorn_config.py ç¤ºä¾‹:**
```python
# Gunicorn é…ç½®æ–‡ä»¶
bind = "0.0.0.0:5000"
workers = 4
worker_class = "sync"
timeout = 30
keepalive = 2
errorlog = "logs/error.log"
accesslog = "logs/access.log"
loglevel = "info"
```

### 2. ä½¿ç”¨ Waitress (Windows)

```bash
# å®‰è£ Waitress
pip install waitress

# å•Ÿå‹•æœå‹™
waitress-serve --host=0.0.0.0 --port=5000 01_flask_api_deployment:app
```

### 3. Docker éƒ¨ç½²

**Dockerfile ç¤ºä¾‹:**
```dockerfile
FROM python:3.8-slim

WORKDIR /app

# è¤‡è£½ä¾è³´æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ä»£ç¢¼
COPY . .

# è¨“ç·´æ¨¡å‹ (å¯é¸ï¼Œä¹Ÿå¯ä»¥æ›è¼‰é è¨“ç·´æ¨¡å‹)
RUN python 01_flask_api_deployment.py --train-only

# æš´éœ²ç«¯å£
EXPOSE 5000

# å•Ÿå‹•æœå‹™
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "01_flask_api_deployment:app"]
```

**æ§‹å»ºå’Œé‹è¡Œ:**
```bash
# æ§‹å»ºé¡åƒ
docker build -t iris-api:1.0 .

# é‹è¡Œå®¹å™¨
docker run -p 5000:5000 iris-api:1.0

# ä½¿ç”¨ docker-compose
docker-compose up -d
```

**docker-compose.yml ç¤ºä¾‹:**
```yaml
version: '3.8'

services:
  iris-api:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
    volumes:
      - ./saved_models:/app/saved_models
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

### 4. Kubernetes éƒ¨ç½²

**deployment.yaml ç¤ºä¾‹:**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: iris-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: iris-api
  template:
    metadata:
      labels:
        app: iris-api
    spec:
      containers:
      - name: iris-api
        image: iris-api:1.0
        ports:
        - containerPort: 5000
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: iris-api-service
spec:
  selector:
    app: iris-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
  type: LoadBalancer
```

---

## ğŸ’¡ æœ€ä½³å¯¦è¸

### 1. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

```python
# ä½¿ç”¨èªç¾©åŒ–ç‰ˆæœ¬è™Ÿ
model_version = "1.2.3"  # MAJOR.MINOR.PATCH

# åœ¨æ–‡ä»¶åä¸­åŒ…å«ç‰ˆæœ¬
model_path = f"models/iris_model_v{model_version}.pkl"

# ä¿å­˜å…ƒæ•¸æ“š
metadata = {
    'version': model_version,
    'trained_date': datetime.now().isoformat(),
    'git_commit': get_git_commit_hash()
}
```

### 2. æ—¥èªŒå’Œç›£æ§

```python
import logging

# é…ç½®çµæ§‹åŒ–æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('api.log'),
        logging.StreamHandler()
    ]
)

# è¨˜éŒ„é—œéµäº‹ä»¶
logger.info(f"Model loaded: {model_version}")
logger.info(f"Prediction made: {prediction}, confidence: {confidence}")
```

### 3. éŒ¯èª¤è™•ç†

```python
# çµ±ä¸€çš„éŒ¯èª¤éŸ¿æ‡‰æ ¼å¼
@app.errorhandler(Exception)
def handle_error(error):
    response = {
        'error': str(error),
        'type': type(error).__name__,
        'timestamp': datetime.now().isoformat()
    }
    logger.error(f"Error: {response}")
    return jsonify(response), 500
```

### 4. è¼¸å…¥é©—è­‰

```python
def validate_features(features, expected_count):
    """é©—è­‰è¼¸å…¥ç‰¹å¾µ"""
    if len(features) != expected_count:
        raise ValueError(f"Expected {expected_count} features")

    if any(np.isnan(features)) or any(np.isinf(features)):
        raise ValueError("Features contain invalid values")

    return True
```

### 5. æ€§èƒ½å„ªåŒ–

- **ä½¿ç”¨æ‰¹é‡é æ¸¬**: å°å¤šå€‹æ¨£æœ¬ä½¿ç”¨ `predict_batch`
- **æ¨¡å‹ç·©å­˜**: åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚åŠ è¼‰æ¨¡å‹ï¼Œé¿å…é‡è¤‡åŠ è¼‰
- **é€£æ¥æ± **: ä½¿ç”¨ `requests.Session()` å¾©ç”¨ HTTP é€£æ¥
- **ç•°æ­¥è™•ç†**: å°æ–¼é•·æ™‚é–“é‹è¡Œçš„ä»»å‹™ï¼Œä½¿ç”¨ä»»å‹™éšŠåˆ— (Celery)

### 6. å®‰å…¨æ€§

```python
from flask_limiter import Limiter
from flask_cors import CORS

# å•Ÿç”¨ CORS
CORS(app)

# é€Ÿç‡é™åˆ¶
limiter = Limiter(app, key_func=get_remote_address)

@app.route('/predict')
@limiter.limit("100 per minute")
def predict():
    # ...
```

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•æ›´æ–°å·²éƒ¨ç½²çš„æ¨¡å‹?

**A**: ä½¿ç”¨ä»¥ä¸‹ç­–ç•¥ä¹‹ä¸€:
1. **è—ç¶ éƒ¨ç½²**: åŒæ™‚é‹è¡Œæ–°èˆŠç‰ˆæœ¬ï¼Œé€æ­¥åˆ‡æ›æµé‡
2. **æ»¾å‹•æ›´æ–°**: é€æ­¥æ›¿æ›å¯¦ä¾‹
3. **å½±å­éƒ¨ç½²**: æ–°æ¨¡å‹æ¥æ”¶æµé‡ä½†ä¸è¿”å›çµæœï¼Œç”¨æ–¼é©—è­‰

```python
# å¯¦ç¾æ¨¡å‹ç†±æ›´æ–°
@app.route('/reload_model', methods=['POST'])
def reload_model():
    global MODEL
    MODEL = joblib.load('new_model.pkl')
    return jsonify({'status': 'Model reloaded'})
```

### Q2: å¦‚ä½•è™•ç†å¤§æ‰¹é‡è«‹æ±‚?

**A**:
- ä½¿ç”¨ç•°æ­¥ä»»å‹™éšŠåˆ— (Celery + Redis)
- å¯¦ç¾æ‰¹è™•ç†ç«¯é»
- é™åˆ¶æœ€å¤§æ‰¹é‡å¤§å°
- ä½¿ç”¨æµå¼éŸ¿æ‡‰

### Q3: å¦‚ä½•ç›£æ§æ¨¡å‹æ€§èƒ½?

**A**:
```python
from prometheus_client import Counter, Histogram

# å®šç¾©æŒ‡æ¨™
prediction_counter = Counter('predictions_total', 'Total predictions')
prediction_latency = Histogram('prediction_latency_seconds', 'Prediction latency')

# è¨˜éŒ„æŒ‡æ¨™
@prediction_latency.time()
def predict():
    prediction_counter.inc()
    # ...
```

### Q4: æ¨¡å‹æ–‡ä»¶å¤ªå¤§æ€éº¼è¾¦?

**A**:
- ä½¿ç”¨æ¨¡å‹å£“ç¸®æŠ€è¡“ (pruning, quantization)
- å°‡æ¨¡å‹å­˜å„²åœ¨å°è±¡å­˜å„² (S3, GCS)
- ä½¿ç”¨æ¨¡å‹æœå‹™æ¡†æ¶ (TensorFlow Serving, TorchServe)

### Q5: å¦‚ä½•å¯¦ç¾ A/B æ¸¬è©¦?

**A**:
```python
import random

@app.route('/predict')
def predict():
    # éš¨æ©Ÿé¸æ“‡æ¨¡å‹
    if random.random() < 0.5:
        model = model_a
        version = 'A'
    else:
        model = model_b
        version = 'B'

    prediction = model.predict(features)

    # è¨˜éŒ„ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬
    log_prediction(features, prediction, version)

    return jsonify(prediction)
```

---

## ğŸ“š å»¶ä¼¸é–±è®€

### å®˜æ–¹æ–‡æª”
- [Flask æ–‡æª”](https://flask.palletsprojects.com/)
- [scikit-learn æ¨¡å‹æŒä¹…åŒ–](https://scikit-learn.org/stable/model_persistence.html)
- [Gunicorn æ–‡æª”](https://docs.gunicorn.org/)

### æ¨è–¦è³‡æº
- **æ›¸ç±**: "Building Machine Learning Powered Applications" by Emmanuel Ameisen
- **èª²ç¨‹**: "Deploying Machine Learning Models in Production" (Coursera)
- **å·¥å…·**: MLflow, Kubeflow, BentoML

### é€²éšä¸»é¡Œ
- Model Serving Frameworks (TensorFlow Serving, TorchServe)
- Feature Stores (Feast, Tecton)
- Model Monitoring (Evidently AI, Arize)
- MLOps Platforms (Kubeflow, MLflow)

---

## ğŸ“ ç¸½çµ

æœ¬æ¨¡å¡Šæ¶µè“‹äº†æ©Ÿå™¨å­¸ç¿’æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹:

âœ… **æ¨¡å‹è¨“ç·´å’Œåºåˆ—åŒ–**: ä½¿ç”¨ joblib ä¿å­˜æ¨¡å‹
âœ… **REST API é–‹ç™¼**: ä½¿ç”¨ Flask æ§‹å»ºç”Ÿç”¢ç´š API
âœ… **å®¢æˆ¶ç«¯é–‹ç™¼**: å°è£æ˜“ç”¨çš„ API å®¢æˆ¶ç«¯
âœ… **æ€§èƒ½æ¸¬è©¦**: å»¶é²ã€ååé‡åˆ†æ
âœ… **ç”Ÿç”¢éƒ¨ç½²**: Dockerã€Kubernetes éƒ¨ç½²æ–¹æ¡ˆ
âœ… **æœ€ä½³å¯¦è¸**: ç‰ˆæœ¬ç®¡ç†ã€ç›£æ§ã€å®‰å…¨æ€§

### ä¸‹ä¸€æ­¥

1. **å¯¦è¸é …ç›®**: éƒ¨ç½²æ‚¨è‡ªå·±çš„æ¨¡å‹
2. **å­¸ç¿’ MLOps**: è‡ªå‹•åŒ– ML å·¥ä½œæµ
3. **æ¢ç´¢å·¥å…·**: TensorFlow Serving, KFServing
4. **é›²ç«¯éƒ¨ç½²**: AWS SageMaker, Azure ML, GCP AI Platform

---

**ä½œè€…**: MLOps å·¥ç¨‹å¸«
**æœ€å¾Œæ›´æ–°**: 2025-11-18
**ç‰ˆæœ¬**: 1.0.0

å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿æäº¤ Issue æˆ– Pull Request!
